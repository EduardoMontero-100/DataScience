{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primitives constructs in text\n",
    "text1 = 'Ethics are built right into the ideals and objectives of the United Nations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primitive tokenization\n",
    "text2 = text1.split(' ')\n",
    "len(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'are',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'and',\n",
       " 'objectives',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'Nations']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'ideals',\n",
       " 'objectives',\n",
       " 'United',\n",
       " 'Nations']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for long words\n",
    "[w for w in text2 if len(w)>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'United', 'Nations']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for capitalize words\n",
    "[w for w in text2 if w.istitle()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'ideals', 'objectives', 'Nations']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words that ends with s\n",
    "[w for w in text2 if w.endswith('s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = 'To be or not to be'\n",
    "text4 = text3.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To', 'be', 'or', 'not', 'to', 'be']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'To', 'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([w.lower() for w in text4 ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([w.lower() for w in text4 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## s.startswith(t)\n",
    "## s.endswith(t)\n",
    "## t in s\n",
    "## s.isupper(), s.islower(), s.istitle()\n",
    "## s.isalpha(), s.isdigit(), s.isalnum()\n",
    "## s.split()\n",
    "## s.splitlines()\n",
    "## s.join(list)\n",
    "## s.strip(), s.rstrip()\n",
    "## s.find(t), s.rfind(t)\n",
    "## s.replace(u,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = 'ouagadougou'\n",
    "text6 = text5.split('ou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'agad', 'g', '']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ouagadougou'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ou'.join(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/eduardo/Datos/repo_personal/DataScience/coursera/excercises_textmining.ipynb Celda 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/eduardo/Datos/repo_personal/DataScience/coursera/excercises_textmining.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text5\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "text5.split('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'u', 'a', 'g', 'a', 'd', 'o', 'u', 'g', 'o', 'u']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the characters\n",
    "list(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'u', 'a', 'g', 'a', 'd', 'o', 'u', 'g', 'o', 'u']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the characters\n",
    "[c for c in text5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '',\n",
       " 'A',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumped',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog.',\n",
       " '']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Cleaning text\n",
    "text8 = '   A quick brown fox jumped over the lazy dog. '\n",
    "text8.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A quick brown fox jumped over the lazy dog.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = text8.strip()\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9.find('o') # where is the first o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A quick brOwn fOx jumped Over the lazy dOg.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9.replace('o', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Esta es una prueba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Esta es otra prueba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esto lo hago para probar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     textos\n",
       "0        Esta es una prueba\n",
       "1       Esta es otra prueba\n",
       "2  Esto lo hago para probar"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'textos': ['Esta es una prueba', \n",
    "                             'Esta es otra prueba', \n",
    "                             'Esto lo hago para probar']})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/eduardo/Datos/repo_personal/DataScience/coursera/excercises_textmining.ipynb Celda 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/eduardo/Datos/repo_personal/DataScience/coursera/excercises_textmining.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mtextos\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "df['textos'].find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    3\n",
       "2    9\n",
       "Name: textos, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['textos'].str.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('UNDHR.txt', 'r') # filename, mode\n",
    "## f.readline(), f.read(), f.read(n)\n",
    "## for line in f: doSomething(line)\n",
    "## f.seek(n) reset the reading position\n",
    "## f.write(message)  write a message to the file (if it is opened in the appropriate mode)\n",
    "## f.close()\n",
    "## f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universal Declaration of Human Rights - English\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reading files line by line\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the full line\n",
    "f.seek(0) # resets the reading\n",
    "text12 = f.read() # it will read the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12534"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13 = text12.splitlines()\n",
    "len(text13) # number of lines. Which ends with a \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universal Declaration of Human Rights - English'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13[0] # first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universal Declaration of Human Rights - English'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('UNDHR.txt', 'r')\n",
    "text14 = f.readline()\n",
    "## removing the last newline character\n",
    "text14.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expresions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text10 = 'Ethics are built right into the ideals and objectives of the United Nations #UNSG @ NY Society for Ethical Culture bit.ly/2guVelr @UN @UN_Women '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'are',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'and',\n",
       " 'objectives',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'Nations',\n",
       " '#UNSG',\n",
       " '@',\n",
       " 'NY',\n",
       " 'Society',\n",
       " 'for',\n",
       " 'Ethical',\n",
       " 'Culture',\n",
       " 'bit.ly/2guVelr',\n",
       " '@UN',\n",
       " '@UN_Women',\n",
       " '']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text11 = text10.split(' ')\n",
    "text11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#UNSG']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finding hashtags\n",
    "[w for w in text11 if w.startswith('#')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', '@UN', '@UN_Women']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## callouts\n",
    "[w for w in text11 if w.startswith('@')]\n",
    "## here is where regular expresion appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@UN', '@UN_Women']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[w for w in text11 if re.search('@[A-Za-z0-9_]+', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular expresions:\n",
    "## . ==> matches with a single character\n",
    "## ^ ==> it indicates the start of the string\n",
    "## $ ==> the end of the string\n",
    "## [] ==> matches one the set of characters within []\n",
    "## [a-z] ==> matches one of the range characters a,b,c,..,z\n",
    "## [^abc] ==> matches a character that is not a,b, or c\n",
    "## a|b ==> matches either a or b, where a and b are strings\n",
    "\n",
    "## \\b matches word boundry\n",
    "## \\d any digit, equivalent to [0-9]\n",
    "## \\D any non-digit, equivalent to [^0-9]\n",
    "## \\s any whitespace\n",
    "## \\S any non-whitespace\n",
    "## \\w alphanumeric character\n",
    "## \\W any non-alphanumeric character\n",
    "\n",
    "## * matches 0 or more times\n",
    "## + matches 1 or more times\n",
    "## ? matches 0 or more times\n",
    "## {n} exactly n repetitions, n>=0\n",
    "## {n,} at least n repetitions\n",
    "## {,n} at most n repetitions\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@UN', '@UN_Women']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text11 if re.search('@\\w+', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'u', 'a', 'a', 'o', 'u', 'o', 'u']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finding specific characters\n",
    "text12 = 'ouagadougou'\n",
    "re.findall(r'[aeiou]', text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g', 'd', 'g']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^aeiou]', text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## regular expresions for dates\n",
    "## 23/10/2022\n",
    "\n",
    "dateStr = '23-10-200\\n23-10-2002\\n23/10/2002\\n23/10/02\\n10/23/2002\\n23 Oct 2002\\n23 October 2002\\nOct 23, 2002\\n October 23, 2002\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23-10-200', '23-10-2002', '23/10/2002', '23/10/02', '10/23/2002']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oct']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}', dateStr)\n",
    "## como esta en parentesis no hace ninguna otra busqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Oct 2002', '23 October 2002']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4}', dateStr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with text data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday:The doctors appointment is at 2:45pm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday: The dentists appointment is at 11:30 am.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday: At 7:00pm, there is a basketball game!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday: Be back home by 11:15 pm at the latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday: Take the train at 08:10 am, arrive at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0       Monday:The doctors appointment is at 2:45pm.\n",
       "1  Tuesday: The dentists appointment is at 11:30 am.\n",
       "2  Wednesday: At 7:00pm, there is a basketball game!\n",
       "3   Thursday: Be back home by 11:15 pm at the latest\n",
       "4  Friday: Take the train at 08:10 am, arrive at ..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time_sentences = ['Monday:The doctors appointment is at 2:45pm.',\n",
    "                  'Tuesday: The dentists appointment is at 11:30 am.',\n",
    "                  'Wednesday: At 7:00pm, there is a basketball game!',\n",
    "                  'Thursday: Be back home by 11:15 pm at the latest',\n",
    "                  'Friday: Take the train at 08:10 am, arrive at 09:00am.'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(time_sentences, columns = ['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44\n",
       "1    49\n",
       "2    49\n",
       "3    48\n",
       "4    54\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     6\n",
       "1     8\n",
       "2     8\n",
       "3    10\n",
       "4    10\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: text, dtype: bool"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.contains('appointment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    4\n",
       "2    3\n",
       "3    4\n",
       "4    8\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.count(r'\\d')\n",
    "# cuenta las veces que aparece un digito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [2, 4, 5]\n",
       "1                [1, 1, 3, 0]\n",
       "2                   [7, 0, 0]\n",
       "3                [1, 1, 1, 5]\n",
       "4    [0, 8, 1, 0, 0, 9, 0, 0]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.findall(r'\\d')\n",
    "# muestra los digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [(2, 45)]\n",
       "1              [(11, 30)]\n",
       "2               [(7, 00)]\n",
       "3              [(11, 15)]\n",
       "4    [(08, 10), (09, 00)]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.findall(r'(\\d?\\d):(\\d\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7614/2023952851.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'].str.replace(r'\\w+day\\b', '???')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            ???:The doctors appointment is at 2:45pm.\n",
       "1        ???: The dentists appointment is at 11:30 am.\n",
       "2          ???: At 7:00pm, there is a basketball game!\n",
       "3          ???: Be back home by 11:15 pm at the latest\n",
       "4    ???: Take the train at 08:10 am, arrive at 09:...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.replace(r'\\w+day\\b', '???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7614/1376844824.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.groups()[0][:3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            Mon:The doctors appointment is at 2:45pm.\n",
       "1        Tue: The dentists appointment is at 11:30 am.\n",
       "2          Wed: At 7:00pm, there is a basketball game!\n",
       "3          Thu: Be back home by 11:15 pm at the latest\n",
       "4    Fri: Take the train at 08:10 am, arrive at 09:...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.groups()[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0   2  45\n",
       "1  11  30\n",
       "2   7  00\n",
       "3  11  15\n",
       "4  08  10"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.extract(r'(\\d?\\d):(\\d\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2:45pm</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>7:00pm</td>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>09:00am</td>\n",
       "      <td>09</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0   1   2   3\n",
       "  match                     \n",
       "0 0       2:45pm   2  45  pm\n",
       "2 0       7:00pm   7  00  pm\n",
       "4 0      09:00am  09  00  am"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.extractall(r'((\\d?\\d):(\\d\\d)?([ap]m))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2:45pm</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>7:00pm</td>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>09:00am</td>\n",
       "      <td>09</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time hour minute period\n",
       "  match                            \n",
       "0 0       2:45pm    2     45     pm\n",
       "2 0       7:00pm    7     00     pm\n",
       "4 0      09:00am   09     00     am"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.extractall(r'(?P<time>(?P<hour>\\d?\\d):(?P<minute>\\d\\d)?(?P<period>[ap]m))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Natural Language Processing task with NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Call me Ishmael .\n",
      "sent2: The family of Dashwood had long been settled in Sussex .\n",
      "sent3: In the beginning God created the heaven and the earth .\n",
      "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
      "sent5: I have a problem with people PMing me to lol JOIN\n",
      "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
      "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
      "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Wall Street Journal>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent7) ## number of tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text7)) ## unique number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cotton',\n",
       " '*T*-61',\n",
       " 'reality',\n",
       " 'geography',\n",
       " '*T*-226',\n",
       " 'subjecting',\n",
       " 'turf',\n",
       " 'weakening',\n",
       " 'anticipates',\n",
       " '41.60']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(text7))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frequency distribution\n",
    "dist = FreqDist(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 4885, 'the': 4045, '.': 3828, 'of': 2319, 'to': 2164, 'a': 1878, 'in': 1572, 'and': 1511, '*-1': 1123, '0': 1099, ...})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = dist.keys()\n",
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist['four'] ## esta palabra aparece 20 veces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['billion',\n",
       " 'company',\n",
       " 'president',\n",
       " 'because',\n",
       " 'market',\n",
       " 'million',\n",
       " 'shares',\n",
       " 'trading',\n",
       " 'program']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## frequent words if len of this word is > 5 and dist >100\n",
    "freqw = [w for w in vocab if len(w)>5 and dist[w]>100]\n",
    "freqw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'lists', 'listing', 'listings']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization and stemming\n",
    "input1 = \"List listed lists listing listings\"\n",
    "# lower case \n",
    "words1 = input1.lower().split(' ')\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'list', 'list', 'list', 'list']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming (looking for the root form of the word)\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in words1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'rights',\n",
       " 'of']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization is a slight variant of stemming\n",
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "udhr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers',\n",
       " 'declar',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'preambl',\n",
       " 'wherea',\n",
       " 'recognit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inher',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalien',\n",
       " 'right',\n",
       " 'of',\n",
       " 'all',\n",
       " 'member',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'famili',\n",
       " 'is',\n",
       " 'the',\n",
       " 'foundat',\n",
       " 'of',\n",
       " 'freedom',\n",
       " ',',\n",
       " 'justic',\n",
       " 'and',\n",
       " 'peac',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'wherea',\n",
       " 'disregard',\n",
       " 'and',\n",
       " 'contempt',\n",
       " 'for',\n",
       " 'human',\n",
       " 'right',\n",
       " 'have',\n",
       " 'result',\n",
       " 'in',\n",
       " 'barbar',\n",
       " 'act',\n",
       " 'which',\n",
       " 'have',\n",
       " 'outrag',\n",
       " 'the',\n",
       " 'conscienc',\n",
       " 'of',\n",
       " 'mankind',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'advent',\n",
       " 'of',\n",
       " 'a',\n",
       " 'world',\n",
       " 'in',\n",
       " 'which',\n",
       " 'human',\n",
       " 'be',\n",
       " 'shall',\n",
       " 'enjoy',\n",
       " 'freedom',\n",
       " 'of',\n",
       " 'speech',\n",
       " 'and',\n",
       " 'belief',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'from',\n",
       " 'fear',\n",
       " 'and',\n",
       " 'want',\n",
       " 'ha',\n",
       " 'been',\n",
       " 'proclaim',\n",
       " 'as',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'aspir',\n",
       " 'of',\n",
       " 'the',\n",
       " 'common',\n",
       " 'peopl',\n",
       " ',',\n",
       " 'wherea',\n",
       " 'it',\n",
       " 'is',\n",
       " 'essenti',\n",
       " ',',\n",
       " 'if',\n",
       " 'man',\n",
       " 'is',\n",
       " 'not',\n",
       " 'to',\n",
       " 'be',\n",
       " 'compel',\n",
       " 'to',\n",
       " 'have',\n",
       " 'recours',\n",
       " ',',\n",
       " 'as',\n",
       " 'a',\n",
       " 'last',\n",
       " 'resort',\n",
       " ',',\n",
       " 'to',\n",
       " 'rebellion',\n",
       " 'against',\n",
       " 'tyranni',\n",
       " 'and',\n",
       " 'oppress',\n",
       " ',',\n",
       " 'that',\n",
       " 'human',\n",
       " 'right',\n",
       " 'should',\n",
       " 'be',\n",
       " 'protect',\n",
       " 'by',\n",
       " 'the',\n",
       " 'rule',\n",
       " 'of',\n",
       " 'law',\n",
       " ',',\n",
       " 'wherea',\n",
       " 'it',\n",
       " 'is',\n",
       " 'essenti',\n",
       " 'to',\n",
       " 'promot',\n",
       " 'the',\n",
       " 'develop',\n",
       " 'of',\n",
       " 'friendli',\n",
       " 'relat',\n",
       " 'between',\n",
       " 'nation',\n",
       " ',',\n",
       " 'wherea',\n",
       " 'the',\n",
       " 'peopl',\n",
       " 'of',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'nation',\n",
       " 'have',\n",
       " 'in',\n",
       " 'the',\n",
       " 'charter',\n",
       " 'reaffirm',\n",
       " 'their',\n",
       " 'faith',\n",
       " 'in',\n",
       " 'fundament',\n",
       " 'human',\n",
       " 'right',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'worth',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'person',\n",
       " 'and',\n",
       " 'in',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'right',\n",
       " 'of',\n",
       " 'men',\n",
       " 'and',\n",
       " 'women',\n",
       " 'and',\n",
       " 'have',\n",
       " 'determin',\n",
       " 'to',\n",
       " 'promot',\n",
       " 'social',\n",
       " 'progress',\n",
       " 'and',\n",
       " 'better',\n",
       " 'standard',\n",
       " 'of',\n",
       " 'life',\n",
       " 'in',\n",
       " 'larger',\n",
       " 'freedom',\n",
       " ',',\n",
       " 'wherea',\n",
       " 'member',\n",
       " 'state',\n",
       " 'have',\n",
       " 'pledg',\n",
       " 'themselv',\n",
       " 'to',\n",
       " 'achiev',\n",
       " ',',\n",
       " 'in',\n",
       " 'cooper',\n",
       " 'with',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'nation',\n",
       " ',',\n",
       " 'the',\n",
       " 'promot',\n",
       " 'of',\n",
       " 'univers',\n",
       " 'respect',\n",
       " 'for',\n",
       " 'and',\n",
       " 'observ',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'and',\n",
       " 'fundament',\n",
       " 'freedom',\n",
       " ',',\n",
       " 'wherea',\n",
       " 'a',\n",
       " 'common',\n",
       " 'understand',\n",
       " 'of',\n",
       " 'these',\n",
       " 'right',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'is',\n",
       " 'of',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'import',\n",
       " 'for',\n",
       " 'the',\n",
       " 'full',\n",
       " 'realiz',\n",
       " 'of',\n",
       " 'thi',\n",
       " 'pledg',\n",
       " ',',\n",
       " 'now',\n",
       " ',',\n",
       " 'therefor',\n",
       " ',',\n",
       " 'the',\n",
       " 'gener',\n",
       " 'assembl',\n",
       " ',',\n",
       " 'proclaim',\n",
       " 'thi',\n",
       " 'univers',\n",
       " 'declar',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'as',\n",
       " 'a',\n",
       " 'common',\n",
       " 'standard',\n",
       " 'of',\n",
       " 'achiev',\n",
       " 'for',\n",
       " 'all',\n",
       " 'peopl',\n",
       " 'and',\n",
       " 'all',\n",
       " 'nation',\n",
       " ',',\n",
       " 'to',\n",
       " 'the',\n",
       " 'end',\n",
       " 'that',\n",
       " 'everi',\n",
       " 'individu',\n",
       " 'and',\n",
       " 'everi',\n",
       " 'organ',\n",
       " 'of',\n",
       " 'societi',\n",
       " ',',\n",
       " 'keep',\n",
       " 'thi',\n",
       " 'declar',\n",
       " 'constantli',\n",
       " 'in',\n",
       " 'mind',\n",
       " ',',\n",
       " 'shall',\n",
       " 'strive',\n",
       " 'by',\n",
       " 'teach',\n",
       " 'and',\n",
       " 'educ',\n",
       " 'to',\n",
       " 'promot',\n",
       " 'respect',\n",
       " 'for',\n",
       " 'these',\n",
       " 'right',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'and',\n",
       " 'by',\n",
       " 'progress',\n",
       " 'measur',\n",
       " ',',\n",
       " 'nation',\n",
       " 'and',\n",
       " 'intern',\n",
       " ',',\n",
       " 'to',\n",
       " 'secur',\n",
       " 'their',\n",
       " 'univers',\n",
       " 'and',\n",
       " 'effect',\n",
       " 'recognit',\n",
       " 'and',\n",
       " 'observ',\n",
       " ',',\n",
       " 'both',\n",
       " 'among',\n",
       " 'the',\n",
       " 'peopl',\n",
       " 'of',\n",
       " 'member',\n",
       " 'state',\n",
       " 'themselv',\n",
       " 'and',\n",
       " 'among',\n",
       " 'the',\n",
       " 'peopl',\n",
       " 'of',\n",
       " 'territori',\n",
       " 'under',\n",
       " 'their',\n",
       " 'jurisdict',\n",
       " '.',\n",
       " 'articl',\n",
       " '1',\n",
       " 'all',\n",
       " 'human',\n",
       " 'be',\n",
       " 'are',\n",
       " 'born',\n",
       " 'free',\n",
       " 'and',\n",
       " 'equal',\n",
       " 'in',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'right',\n",
       " '.',\n",
       " 'they',\n",
       " 'are',\n",
       " 'endow',\n",
       " 'with',\n",
       " 'reason',\n",
       " 'and',\n",
       " 'conscienc',\n",
       " 'and',\n",
       " 'should',\n",
       " 'act',\n",
       " 'toward',\n",
       " 'one',\n",
       " 'anoth',\n",
       " 'in',\n",
       " 'a',\n",
       " 'spirit',\n",
       " 'of',\n",
       " 'brotherhood',\n",
       " '.',\n",
       " 'articl',\n",
       " '2',\n",
       " 'everyon',\n",
       " 'is',\n",
       " 'entitl',\n",
       " 'to',\n",
       " 'all',\n",
       " 'the',\n",
       " 'right',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'set',\n",
       " 'forth',\n",
       " 'in',\n",
       " 'thi',\n",
       " 'declar',\n",
       " ',',\n",
       " 'without',\n",
       " 'distinct',\n",
       " 'of',\n",
       " 'ani',\n",
       " 'kind',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'race',\n",
       " ',',\n",
       " 'colour',\n",
       " ',',\n",
       " 'sex',\n",
       " ',',\n",
       " 'languag',\n",
       " ',',\n",
       " 'religion',\n",
       " ',',\n",
       " 'polit',\n",
       " 'or',\n",
       " 'other',\n",
       " 'opinion',\n",
       " ',',\n",
       " 'nation',\n",
       " 'or',\n",
       " 'social',\n",
       " 'origin',\n",
       " ',',\n",
       " 'properti',\n",
       " ',',\n",
       " 'birth',\n",
       " 'or',\n",
       " 'other',\n",
       " 'statu',\n",
       " '.',\n",
       " 'furthermor',\n",
       " ',',\n",
       " 'no',\n",
       " 'distinct',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'made',\n",
       " 'on',\n",
       " 'the',\n",
       " 'basi',\n",
       " 'of',\n",
       " 'the',\n",
       " 'polit',\n",
       " ',',\n",
       " 'jurisdict',\n",
       " 'or',\n",
       " 'intern',\n",
       " 'statu',\n",
       " 'of',\n",
       " 'the',\n",
       " 'countri',\n",
       " 'or',\n",
       " 'territori',\n",
       " 'to',\n",
       " 'which',\n",
       " 'a',\n",
       " 'person',\n",
       " 'belong',\n",
       " ',',\n",
       " 'whether',\n",
       " 'it',\n",
       " 'be',\n",
       " 'independ',\n",
       " ',',\n",
       " 'trust',\n",
       " ',',\n",
       " 'non',\n",
       " '-',\n",
       " 'self',\n",
       " '-',\n",
       " 'govern',\n",
       " 'or',\n",
       " 'under',\n",
       " 'ani',\n",
       " 'other',\n",
       " 'limit',\n",
       " 'of',\n",
       " 'sovereignti',\n",
       " '.',\n",
       " 'articl',\n",
       " '3',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'life',\n",
       " ',',\n",
       " 'liberti',\n",
       " 'and',\n",
       " 'secur',\n",
       " 'of',\n",
       " 'person',\n",
       " '.',\n",
       " 'articl',\n",
       " '4',\n",
       " 'no',\n",
       " 'one',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'held',\n",
       " 'in',\n",
       " 'slaveri',\n",
       " 'or',\n",
       " 'servitud',\n",
       " ';',\n",
       " 'slaveri',\n",
       " 'and',\n",
       " 'the',\n",
       " 'slave',\n",
       " 'trade',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'prohibit',\n",
       " 'in',\n",
       " 'all',\n",
       " 'their',\n",
       " 'form',\n",
       " '.',\n",
       " 'articl',\n",
       " '5',\n",
       " 'no',\n",
       " 'one',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'tortur',\n",
       " 'or',\n",
       " 'to',\n",
       " 'cruel',\n",
       " ',',\n",
       " 'inhuman',\n",
       " 'or',\n",
       " 'degrad',\n",
       " 'treatment',\n",
       " 'or',\n",
       " 'punish',\n",
       " '.',\n",
       " 'articl',\n",
       " '6',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'recognit',\n",
       " 'everywher',\n",
       " 'as',\n",
       " 'a',\n",
       " 'person',\n",
       " 'befor',\n",
       " 'the',\n",
       " 'law',\n",
       " '.',\n",
       " 'articl',\n",
       " '7',\n",
       " 'all',\n",
       " 'are',\n",
       " 'equal',\n",
       " 'befor',\n",
       " 'the',\n",
       " 'law',\n",
       " 'and',\n",
       " 'are',\n",
       " 'entitl',\n",
       " 'without',\n",
       " 'ani',\n",
       " 'discrimin',\n",
       " 'to',\n",
       " 'equal',\n",
       " 'protect',\n",
       " 'of',\n",
       " 'the',\n",
       " 'law',\n",
       " '.',\n",
       " 'all',\n",
       " 'are',\n",
       " 'entitl',\n",
       " 'to',\n",
       " 'equal',\n",
       " 'protect',\n",
       " 'against',\n",
       " 'ani',\n",
       " 'discrimin',\n",
       " 'in',\n",
       " 'violat',\n",
       " 'of',\n",
       " 'thi',\n",
       " 'declar',\n",
       " 'and',\n",
       " 'against',\n",
       " 'ani',\n",
       " 'incit',\n",
       " 'to',\n",
       " 'such',\n",
       " 'discrimin',\n",
       " '.',\n",
       " 'articl',\n",
       " '8',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'an',\n",
       " 'effect',\n",
       " 'remedi',\n",
       " 'by',\n",
       " 'the',\n",
       " 'compet',\n",
       " 'nation',\n",
       " 'tribun',\n",
       " 'for',\n",
       " 'act',\n",
       " 'violat',\n",
       " 'the',\n",
       " 'fundament',\n",
       " 'right',\n",
       " 'grant',\n",
       " 'him',\n",
       " 'by',\n",
       " 'the',\n",
       " 'constitut',\n",
       " 'or',\n",
       " 'by',\n",
       " 'law',\n",
       " '.',\n",
       " 'articl',\n",
       " '9',\n",
       " 'no',\n",
       " 'one',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'arbitrari',\n",
       " 'arrest',\n",
       " ',',\n",
       " 'detent',\n",
       " 'or',\n",
       " 'exil',\n",
       " '.',\n",
       " 'articl',\n",
       " '10',\n",
       " 'everyon',\n",
       " 'is',\n",
       " 'entitl',\n",
       " 'in',\n",
       " 'full',\n",
       " 'equal',\n",
       " 'to',\n",
       " 'a',\n",
       " 'fair',\n",
       " 'and',\n",
       " 'public',\n",
       " 'hear',\n",
       " 'by',\n",
       " 'an',\n",
       " 'independ',\n",
       " 'and',\n",
       " 'imparti',\n",
       " 'tribun',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'determin',\n",
       " 'of',\n",
       " 'hi',\n",
       " 'right',\n",
       " 'and',\n",
       " 'oblig',\n",
       " 'and',\n",
       " 'of',\n",
       " 'ani',\n",
       " 'crimin',\n",
       " 'charg',\n",
       " 'against',\n",
       " 'him',\n",
       " '.',\n",
       " 'articl',\n",
       " '11',\n",
       " 'everyon',\n",
       " 'charg',\n",
       " 'with',\n",
       " 'a',\n",
       " 'penal',\n",
       " 'offenc',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'be',\n",
       " 'presum',\n",
       " 'innoc',\n",
       " 'until',\n",
       " 'prove',\n",
       " 'guilti',\n",
       " 'accord',\n",
       " 'to',\n",
       " 'law',\n",
       " 'in',\n",
       " 'a',\n",
       " 'public',\n",
       " 'trial',\n",
       " 'at',\n",
       " 'which',\n",
       " 'he',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'all',\n",
       " 'the',\n",
       " 'guarante',\n",
       " 'necessari',\n",
       " 'for',\n",
       " 'hi',\n",
       " 'defenc',\n",
       " '.',\n",
       " 'no',\n",
       " 'one',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'held',\n",
       " 'guilti',\n",
       " 'of',\n",
       " 'ani',\n",
       " 'penal',\n",
       " 'offenc',\n",
       " 'on',\n",
       " 'account',\n",
       " 'of',\n",
       " 'ani',\n",
       " 'act',\n",
       " 'or',\n",
       " 'omiss',\n",
       " 'which',\n",
       " 'did',\n",
       " 'not',\n",
       " 'constitut',\n",
       " 'a',\n",
       " 'penal',\n",
       " 'offenc',\n",
       " ',',\n",
       " 'under',\n",
       " 'nation',\n",
       " 'or',\n",
       " 'intern',\n",
       " 'law',\n",
       " ',',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'when',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'commit',\n",
       " '.',\n",
       " 'nor',\n",
       " 'shall',\n",
       " 'a',\n",
       " 'heavier',\n",
       " 'penalti',\n",
       " 'be',\n",
       " 'impos',\n",
       " 'than',\n",
       " 'the',\n",
       " 'one',\n",
       " 'that',\n",
       " 'wa',\n",
       " 'applic',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'the',\n",
       " 'penal',\n",
       " 'offenc',\n",
       " 'wa',\n",
       " 'commit',\n",
       " '.',\n",
       " 'articl',\n",
       " '12',\n",
       " 'no',\n",
       " 'one',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'arbitrari',\n",
       " 'interfer',\n",
       " 'with',\n",
       " 'hi',\n",
       " 'privaci',\n",
       " ',',\n",
       " 'famili',\n",
       " ',',\n",
       " 'home',\n",
       " 'or',\n",
       " 'correspond',\n",
       " ',',\n",
       " 'nor',\n",
       " 'to',\n",
       " 'attack',\n",
       " 'upon',\n",
       " 'hi',\n",
       " 'honour',\n",
       " 'and',\n",
       " 'reput',\n",
       " '.',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'the',\n",
       " 'protect',\n",
       " 'of',\n",
       " 'the',\n",
       " 'law',\n",
       " 'against',\n",
       " 'such',\n",
       " 'interfer',\n",
       " 'or',\n",
       " 'attack',\n",
       " '.',\n",
       " 'articl',\n",
       " '13',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'freedom',\n",
       " 'of',\n",
       " 'movement',\n",
       " 'and',\n",
       " 'resid',\n",
       " 'within',\n",
       " 'the',\n",
       " 'border',\n",
       " 'of',\n",
       " 'each',\n",
       " 'state',\n",
       " '.',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'leav',\n",
       " 'ani',\n",
       " 'countri',\n",
       " ',',\n",
       " 'includ',\n",
       " 'hi',\n",
       " 'own',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'return',\n",
       " 'to',\n",
       " 'hi',\n",
       " 'countri',\n",
       " '.',\n",
       " 'articl',\n",
       " '14',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'seek',\n",
       " 'and',\n",
       " 'to',\n",
       " 'enjoy',\n",
       " 'in',\n",
       " 'other',\n",
       " 'countri',\n",
       " 'asylum',\n",
       " 'from',\n",
       " 'persecut',\n",
       " '.',\n",
       " 'thi',\n",
       " 'right',\n",
       " 'may',\n",
       " 'not',\n",
       " 'be',\n",
       " 'invok',\n",
       " 'in',\n",
       " 'the',\n",
       " 'case',\n",
       " 'of',\n",
       " 'prosecut',\n",
       " 'genuin',\n",
       " 'aris',\n",
       " 'from',\n",
       " 'non',\n",
       " '-',\n",
       " 'polit',\n",
       " 'crime',\n",
       " 'or',\n",
       " 'from',\n",
       " 'act',\n",
       " 'contrari',\n",
       " 'to',\n",
       " 'the',\n",
       " 'purpos',\n",
       " 'and',\n",
       " 'principl',\n",
       " 'of',\n",
       " 'the',\n",
       " 'unit',\n",
       " 'nation',\n",
       " '.',\n",
       " 'articl',\n",
       " '15',\n",
       " 'everyon',\n",
       " 'ha',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'a',\n",
       " 'nation',\n",
       " '.',\n",
       " 'no',\n",
       " 'one',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'arbitrarili',\n",
       " 'depriv',\n",
       " 'of',\n",
       " 'hi',\n",
       " 'nation',\n",
       " 'nor',\n",
       " 'deni',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'chang',\n",
       " 'hi',\n",
       " 'nation',\n",
       " '.',\n",
       " 'articl',\n",
       " '16',\n",
       " 'men',\n",
       " 'and',\n",
       " 'women',\n",
       " 'of',\n",
       " 'full',\n",
       " 'age',\n",
       " ',',\n",
       " 'without',\n",
       " 'ani',\n",
       " 'limit',\n",
       " 'due',\n",
       " 'to',\n",
       " 'race',\n",
       " ',',\n",
       " 'nation',\n",
       " 'or',\n",
       " 'religion',\n",
       " ',',\n",
       " 'have',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'marri',\n",
       " 'and',\n",
       " 'to',\n",
       " 'found',\n",
       " 'a',\n",
       " 'famili',\n",
       " '.',\n",
       " 'they',\n",
       " 'are',\n",
       " 'entitl',\n",
       " 'to',\n",
       " 'equal',\n",
       " 'right',\n",
       " 'as',\n",
       " 'to',\n",
       " 'marriag',\n",
       " ',',\n",
       " 'dure',\n",
       " 'marriag',\n",
       " 'and',\n",
       " 'at',\n",
       " 'it',\n",
       " 'dissolut',\n",
       " '.',\n",
       " 'marriag',\n",
       " 'shall',\n",
       " 'be',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(t) for t in udhr]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lemmatization: Stemming, but resulting stems are all valid words\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "[WNlemma.lemmatize(t) for t in udhr[:20]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children',\n",
       " 'should',\n",
       " 'not',\n",
       " 'drink',\n",
       " 'a',\n",
       " 'sugary',\n",
       " 'drink',\n",
       " 'before',\n",
       " 'bed.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text11 = \"Children should not drink a sugary drink before bed.\"\n",
    "text11.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children',\n",
       " 'should',\n",
       " 'not',\n",
       " 'drink',\n",
       " 'a',\n",
       " 'sugary',\n",
       " 'drink',\n",
       " 'before',\n",
       " 'bed',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## how you would split sentences from a long text string\n",
    "text12 = \"This is the first sentence. A gallon of milk in the U.S costs $2.99. Is this this the third sentence. Yes, it is!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence.',\n",
       " 'A gallon of milk in the U.S costs $2.99.',\n",
       " 'Is this this the third sentence.',\n",
       " 'Yes, it is!']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sent_tokenizer\n",
    "sentences = nltk.sent_tokenize(text12)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Natural Language Task "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.help.upenn_tagset('MD') ##Modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('CC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text11 = \"Children should not drink a sugary drink before bed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text13 = nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children', 'NNP'),\n",
       " ('should', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('drink', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('sugary', 'JJ'),\n",
       " ('drink', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('bed', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk tokenizer getting the postags\n",
    "nltk.pos_tag(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ambiguity in POST Tagging\n",
    "text14 = nltk.word_tokenize(\"Visiting aunts can be a nuisance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Visiting', 'VBG'),\n",
       " ('aunts', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('nuisance', 'NN')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alice', 'loves', 'Bob']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text15 = nltk.word_tokenize('Alice loves Bob')\n",
    "text15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "NP -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")\n",
    "# there could be ambiguity even if the sentence is grammatically correct \n",
    "# we can write a grammar configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar)\n",
    "trees = parser.parse_all(text15)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nltk and Parse Tree Collection\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "text17 = treebank.parsed_sents('wsj_0001.mrg')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "print(text17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
